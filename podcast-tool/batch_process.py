#!/usr/bin/env python3
"""
æ‰¹é‡é¢„è®¡ç®—è„šæœ¬ â€” ä»Ž top_podcasts.json è¯»å–æ’­å®¢åˆ—è¡¨ï¼Œé€ä¸ªå¤„ç†æœ€æ–° episodeã€‚
ç”¨å®Œ Deepgram é¢åº¦å‰å°½é‡å¤šè·‘ã€‚

ç”¨æ³•ï¼š
  python3 batch_process.py                    # æ¯ä¸ªæ’­å®¢è·‘æœ€æ–° 3 é›†
  python3 batch_process.py --per-podcast 5    # æ¯ä¸ªæ’­å®¢è·‘æœ€æ–° 5 é›†
  python3 batch_process.py --start 10         # ä»Žç¬¬ 10 åå¼€å§‹è·‘
  python3 batch_process.py --dry-run          # åªåˆ—å‡ºè¦è·‘çš„ episodeï¼Œä¸å®žé™…å¤„ç†
"""

import json
import re
import sys
import os
import time
import argparse
from pathlib import Path

# ç¡®ä¿èƒ½ import åŒç›®å½•æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent))

import httpx
from bs4 import BeautifulSoup

BASE_DIR = Path(__file__).parent.resolve()
OUTPUT_DIR = BASE_DIR / "output"
TOP_PODCASTS = BASE_DIR / "top_podcasts.json"
PROGRESS_FILE = BASE_DIR / "batch_progress.json"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/120.0.0.0 Safari/537.36",
    "Accept-Language": "zh-CN,zh;q=0.9",
}


def is_valid_episode_id(eid):
    return bool(re.fullmatch(r"[a-f0-9]{20,30}", eid))


def is_already_processed(episode_id):
    """æ£€æŸ¥æ˜¯å¦å·²æœ‰å®Œæ•´çš„å¯è§†åŒ–æ–‡ä»¶"""
    viz = OUTPUT_DIR / episode_id / "visualization.html"
    return viz.exists()


def fetch_episode_list(podcast_url, limit=5):
    """ä»Žå°å®‡å®™æ’­å®¢ä¸»é¡µæŠ“å–æœ€æ–° episode åˆ—è¡¨"""
    print(f"  ðŸ“¡ æŠ“å– episode åˆ—è¡¨: {podcast_url}")
    try:
        with httpx.Client(headers=HEADERS, follow_redirects=True, timeout=30) as client:
            resp = client.get(podcast_url)
            resp.raise_for_status()
    except Exception as e:
        print(f"  âŒ æŠ“å–å¤±è´¥: {e}")
        return []

    soup = BeautifulSoup(resp.text, "html.parser")
    episodes = []
    seen = set()

    # ä»Žé¡µé¢ä¸­æå–æ‰€æœ‰ episode é“¾æŽ¥
    for tag in soup.find_all(["a", "link"], href=True):
        href = tag["href"]
        match = re.search(r"/episode/([a-f0-9]{20,30})", href)
        if match:
            eid = match.group(1)
            if eid not in seen:
                seen.add(eid)
                episodes.append({
                    "id": eid,
                    "url": f"https://www.xiaoyuzhoufm.com/episode/{eid}",
                })

    # ä¹Ÿä»Žé¡µé¢æ–‡æœ¬ä¸­æ­£åˆ™æœç´¢
    for match in re.finditer(r"/episode/([a-f0-9]{20,30})", resp.text):
        eid = match.group(1)
        if eid not in seen:
            seen.add(eid)
            episodes.append({
                "id": eid,
                "url": f"https://www.xiaoyuzhoufm.com/episode/{eid}",
            })

    print(f"  ðŸ“‹ æ‰¾åˆ° {len(episodes)} ä¸ª episode")
    return episodes[:limit]


def process_episode(episode_url):
    """è°ƒç”¨çŽ°æœ‰æµæ°´çº¿å¤„ç†å•ä¸ª episode"""
    from fetcher import fetch_metadata
    from transcribe import transcribe_audio
    from analyzer import analyze_transcript
    from generator import render

    # Step 1: å…ƒæ•°æ®
    metadata = fetch_metadata(episode_url)
    episode_id = metadata["episode_id"]

    if not metadata.get("audio_url"):
        print(f"  âš ï¸  è·³è¿‡ï¼ˆæ— éŸ³é¢‘/ä»˜è´¹å†…å®¹ï¼‰: {metadata.get('title', '')[:40]}")
        return {"status": "skipped", "reason": "no_audio", "episode_id": episode_id}

    output_dir = OUTPUT_DIR / episode_id
    output_dir.mkdir(parents=True, exist_ok=True)

    (output_dir / "metadata.json").write_text(
        json.dumps(metadata, ensure_ascii=False, indent=2), encoding="utf-8"
    )

    # Step 2: è½¬å½•
    txt_path = output_dir / "transcript.txt"
    if txt_path.exists() and txt_path.stat().st_size > 100:
        print(f"  â­ï¸  è½¬å½•æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡")
    else:
        print(f"  ðŸŽ™ï¸  Deepgram è½¬å½•ä¸­...")
        tr_result = transcribe_audio(
            url=metadata["audio_url"],
            language="zh",
            output_prefix="transcript",
            output_dir=str(output_dir),
        )
        if not tr_result["success"]:
            error = tr_result["error"]
            # æ£€æµ‹é¢åº¦ç”¨å®Œ
            if "402" in str(error) or "insufficient" in str(error).lower() or "quota" in str(error).lower():
                print(f"\nðŸš« Deepgram é¢åº¦å·²ç”¨å®Œï¼")
                return {"status": "quota_exhausted", "episode_id": episode_id}
            raise RuntimeError(f"è½¬å½•å¤±è´¥: {error}")

    # Step 3: AI åˆ†æž
    episode_json_path = output_dir / "episode.json"
    if episode_json_path.exists() and episode_json_path.stat().st_size > 100:
        print(f"  â­ï¸  åˆ†æžæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡")
    else:
        print(f"  ðŸ¤– AI åˆ†æžä¸­...")
        analyze_transcript(str(txt_path), str(episode_json_path), metadata)

    # Step 4: ç”Ÿæˆ HTML
    viz_path = output_dir / "visualization.html"
    print(f"  ðŸŽ¨ ç”Ÿæˆå¯è§†åŒ–...")
    render(str(episode_json_path), str(viz_path))

    duration = metadata.get("duration_sec", 0)
    cost = round(duration / 60 * 0.0056, 3) if duration else 0
    print(f"  âœ… å®Œæˆ! æ—¶é•¿ {duration//60}åˆ†{duration%60}ç§’, é¢„ä¼° Deepgram æˆæœ¬ ${cost}")

    return {
        "status": "done",
        "episode_id": episode_id,
        "title": metadata.get("title", ""),
        "duration_sec": duration,
        "cost_usd": cost,
    }


def load_progress():
    """åŠ è½½è¿›åº¦æ–‡ä»¶"""
    if PROGRESS_FILE.exists():
        return json.loads(PROGRESS_FILE.read_text(encoding="utf-8"))
    return {"processed": [], "skipped": [], "failed": [], "total_cost_usd": 0}


def save_progress(progress):
    """ä¿å­˜è¿›åº¦"""
    PROGRESS_FILE.write_text(
        json.dumps(progress, ensure_ascii=False, indent=2), encoding="utf-8"
    )


def main():
    parser = argparse.ArgumentParser(description="æ‰¹é‡é¢„è®¡ç®—æ’­å®¢å¯è§†åŒ–")
    parser.add_argument("--per-podcast", type=int, default=3, help="æ¯ä¸ªæ’­å®¢å¤„ç†æœ€æ–°å‡ é›† (é»˜è®¤ 3)")
    parser.add_argument("--start", type=int, default=1, help="ä»Žç¬¬å‡ åæ’­å®¢å¼€å§‹ (é»˜è®¤ 1)")
    parser.add_argument("--end", type=int, default=None, help="åˆ°ç¬¬å‡ åæ’­å®¢ç»“æŸ")
    parser.add_argument("--dry-run", action="store_true", help="åªåˆ—å‡ºè¦è·‘çš„ episodeï¼Œä¸å®žé™…å¤„ç†")
    args = parser.parse_args()

    # åŠ è½½æ’­å®¢åˆ—è¡¨
    podcasts = json.loads(TOP_PODCASTS.read_text(encoding="utf-8"))
    podcasts = [p for p in podcasts if p["rank"] >= args.start]
    if args.end:
        podcasts = [p for p in podcasts if p["rank"] <= args.end]

    print(f"{'='*60}")
    print(f"  æ‰¹é‡é¢„è®¡ç®— â€” {len(podcasts)} ä¸ªæ’­å®¢, æ¯ä¸ªæœ€æ–° {args.per_podcast} é›†")
    print(f"{'='*60}\n")

    progress = load_progress()
    processed_ids = set(progress["processed"])
    total_cost = progress["total_cost_usd"]
    total_done = 0
    total_skipped = 0

    for podcast in podcasts:
        name = podcast["name"]
        rank = podcast["rank"]
        url = podcast["podcast_url"]

        print(f"\n{'â”€'*60}")
        print(f"ðŸŽ§ [{rank}] {name} ({podcast.get('subscribers', '')})")
        print(f"   {url}")

        # èŽ·å– episode åˆ—è¡¨
        episodes = fetch_episode_list(url, limit=args.per_podcast)
        if not episodes:
            print(f"  âš ï¸  æœªæ‰¾åˆ° episodeï¼Œè·³è¿‡")
            continue

        for ep in episodes:
            eid = ep["id"]

            # è·³è¿‡å·²å¤„ç†çš„
            if eid in processed_ids or is_already_processed(eid):
                print(f"  â­ï¸  å·²å¤„ç†: {eid[:12]}...")
                total_skipped += 1
                continue

            if args.dry_run:
                print(f"  ðŸ“ å¾…å¤„ç†: {ep['url']}")
                continue

            # å¤„ç†
            print(f"\n  â–¶ å¤„ç†: {ep['url']}")
            try:
                result = process_episode(ep["url"])

                if result["status"] == "quota_exhausted":
                    print(f"\n{'='*60}")
                    print(f"  Deepgram é¢åº¦å·²ç”¨å®Œ!")
                    print(f"  æœ¬æ¬¡å…±å¤„ç†: {total_done} é›†")
                    print(f"  ç´¯è®¡é¢„ä¼°æˆæœ¬: ${total_cost:.3f}")
                    print(f"{'='*60}")
                    save_progress(progress)
                    sys.exit(0)

                if result["status"] == "done":
                    total_done += 1
                    cost = result.get("cost_usd", 0)
                    total_cost += cost
                    progress["processed"].append(eid)
                    progress["total_cost_usd"] = round(total_cost, 3)
                    processed_ids.add(eid)
                elif result["status"] == "skipped":
                    progress["skipped"].append(eid)
                    total_skipped += 1

            except Exception as e:
                print(f"  âŒ å¤±è´¥: {e}")
                progress["failed"].append({"id": eid, "error": str(e)[:200]})

            # æ¯é›†å¤„ç†å®Œä¿å­˜è¿›åº¦
            save_progress(progress)

            # è¯·æ±‚é—´éš”ï¼Œé¿å…è¢«é£ŽæŽ§
            time.sleep(2)

        # æ’­å®¢é—´éš”
        time.sleep(3)

    # æœ€ç»ˆæ±‡æ€»
    print(f"\n{'='*60}")
    print(f"  æ‰¹é‡å¤„ç†å®Œæˆ!")
    print(f"  å¤„ç†æˆåŠŸ: {total_done} é›†")
    print(f"  è·³è¿‡: {total_skipped} é›†")
    print(f"  å¤±è´¥: {len(progress['failed'])} é›†")
    print(f"  ç´¯è®¡ Deepgram é¢„ä¼°æˆæœ¬: ${total_cost:.3f} (Â¥{total_cost*7.1:.1f})")
    print(f"{'='*60}")
    save_progress(progress)


if __name__ == "__main__":
    main()
